{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICMAG/Fuzzy/blob/main/KerasLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufovKlinoM-j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vofA6jmoxke"
      },
      "source": [
        "A temperature-forecasting example\n",
        "Throughout this chapter, all of our code examples will target a single problem: predicting the temperature 24 hours in the future, given a timeseries of hourly measurements of quantities such as atmospheric pressure and humidity, recorded over the\n",
        "recent past by a set of sensors on the roof of a building. As you will see, it’s a fairly challenging problem!\n",
        " We’ll use this temperature-forecasting task to highlight what makes timeseries data\n",
        "fundamentally different from the kinds of datasets you’ve encountered so far. You’ll\n",
        "282 CHAPTER 10 Deep learning for timeseries\n",
        "see that densely connected networks and convolutional networks aren’t well-equipped\n",
        "to deal with this kind of dataset, while a different kind of machine learning technique—recurrent neural networks (RNNs)—really shines on this type of problem.\n",
        " We’ll work with a weather timeseries dataset recorded at the weather station at the\n",
        "Max Planck Institute for Biogeochemistry in Jena, Germany.1\n",
        " In this dataset, 14 different quantities (such as temperature, pressure, humidity, wind direction, and so on)\n",
        "were recorded every 10 minutes over several years. The original data goes back to\n",
        "2003, but the subset of the data we’ll download is limited to 2009–2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74GfvMJkozc4",
        "outputId": "44d250a0-7ade-4285-b0dd-d63e5331cc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-01 16:35:25--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.234.56, 52.217.129.200, 52.216.58.248, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.234.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  13.9MB/s    in 0.9s    \n",
            "\n",
            "2022-12-01 16:35:27 (13.9 MB/s) - ‘jena_climate_2009_2016.csv.zip’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "  inflating: jena_climate_2009_2016.csv  \n",
            "  inflating: __MACOSX/._jena_climate_2009_2016.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTaAYFRdo8Wg"
      },
      "source": [
        "Cargar y analizar el Data SET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOC2y7rTpDub",
        "outputId": "ce27b88b-9d69-4ba7-b00f-d4260323d973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
        "with open(fname) as f:\n",
        " data = f.read()\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfN4-vyxpxHG"
      },
      "source": [
        "Now, convert all 420,551 lines of data into NumPy arrays: one array for the temperature (in degrees Celsius), and another one for the rest of the data—the features we\n",
        "will use to predict future temperatures. Note that we discard the “Date Time” column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "KQ0Z4ebdp0PT",
        "outputId": "499ac3e9-bb5b-4f93-ac9f-f0d5f6601a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(420451,)\n",
            "<memory at 0x7fdf33bf4d00>\n",
            "(420451, 14)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "  values = [float(x) for x in line.split(\",\")[1:]]\n",
        "  temperature[i] = values[1]\n",
        "  raw_data[i, :] = values[:]\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(range(len(temperature)), temperature)\n",
        "plt.plot(range(1440), temperature[:1440])\n",
        "print(temperature.shape)\n",
        "print(temperature.data)\n",
        "print(raw_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "813a2P_6sWLQ"
      },
      "source": [
        "On this plot, you can see daily periodicity, especially for the last 4 days. Also note that\n",
        "this 10-day period must be coming from a fairly cold winter month.\n",
        "With our dataset, if you were trying to predict average temperature for the next month\n",
        "given a few months of past data, the problem would be easy, due to the reliable yearscale periodicity of the data. But looking at the data over a scale of days, the temperature\n",
        "looks a lot more chaotic. Is this timeseries predictable at a daily scale? Let’s find out.\n",
        "In all our experiments, we’ll use the first 50% of the data for training, the following 25% for validation, and the last 25% for testing. When working with timeseries\n",
        "data, it’s important to use validation and test data that is more recent than the training data, because you’re trying to predict the future given the past, not the reverse,\n",
        "and your validation/test splits should reflect that. Some problems happen to be considerably simpler if you reverse the time axis!\n",
        ">>> num_train_samples = int(0.5 * len(raw_data))\n",
        ">>> num_val_samples = int(0.25 * len(raw_data))\n",
        ">>> num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "Always look for periodicity in your data\n",
        "Periodicity over multiple timescales is an important and very common property of\n",
        "timeseries data. Whether you’re looking at the weather, mall parking occupancy, traffic to a website, sales of a grocery store, or steps logged in a fitness tracker, you’ll\n",
        "see daily cycles and yearly cycles (human-generated data also tends to feature\n",
        "weekly cycles). When exploring your data, make sure to look for these patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C9kDk2Xsdoy"
      },
      "source": [
        "Listing 10.5 Computing the number of samples we’ll use for each data split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDs9K0hXsjG5",
        "outputId": "2f637ab9-8d9d-4a65-d58c-ebd5d6a269a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ],
      "source": [
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0LRxqmOs8Pf"
      },
      "source": [
        "Preparing the data\n",
        "The exact formulation of the problem will be as follows: given data covering the previous five days and sampled once per hour, can we predict the temperature in 24 hours?\n",
        "First, let’s preprocess the data to a format a neural network can ingest. This is\n",
        "easy: the data is already numerical, so you don’t need to do any vectorization. But each timeseries in the data is on a different scale (for example, atmospheric pressure, measured in mbar, is around 1,000, while H2OC, measured in millimoles per mole, is around 3). We’ll normalize each timeseries independently so that they all take small values on a similar scale. We’re going to use the first 210,225 timesteps as training data, so we’ll compute the mean and standard deviation only on this fraction of the data.\n",
        "Next, let’s create a Dataset object that yields batches of data from the past five days along with a target temperature 24 hours in the future. Because the samples in the dataset are highly redundant (sample N and sample N + 1 will have most of their timesteps in common), it would be wasteful to explicitly allocate memory for every sample. Instead, we’ll generate the samples on the fly while only keeping in memory the original raw_data and temperature arrays, and nothing more. We could easily write a Python generator to do this, but there’s a built-in dataset utility in Keras that does just that (timeseries_dataset_from_array()), so we can save ourselves some work by using it. You can generally use it for any kind of timeseries forecasting task. Understanding timeseries_dataset_from_array() To understand what timeseries_dataset_from_array() does, let’s look at a simple example. The general idea is that you provide an array of timeseries data (the data argument , and timeseries_dataset_from_array() gives you windows extracted from the original timeseries (we’ll call them “sequences”). For example, if you use data = [0 1 2 3 4 5 6] and sequence_length=3, then timeseries_dataset_from_array() will generate the following samples: [0 1 2], [1 2 3], [2 3 4], [3 4 5], [4 5 6]. (continued) You can also pass a targets argument (an array) to timeseries_dataset_ from_array(). The first entry of the targets array should match the desired target for the first sequence that will be generated from the data array. So if you’re doing timeseries forecasting, targets should be the same array as data, offset by some amount. For instance, with data = [0 1 2 3 4 5 6 …] and sequence_length=3, you could create a dataset to predict the next step in the series by passing targets = [3 4 5 6 …]. Let’s try it:\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "int_sequence = np.arange(10)\n",
        "dummy_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "data=int_sequence[:-3],\n",
        "targets=int_sequence[3:],\n",
        "sequence_length=3,\n",
        "batch_size=2, )\n",
        "for inputs, targets in dummy_dataset:\n",
        "for i in range(inputs.shape[0]):\n",
        "print([int(x) for x in inputs[i]], int(targets[i]))\n",
        "This bit of code prints the following results:\n",
        "[0, 1, 2] 3\n",
        "[1, 2, 3] 4\n",
        "[2, 3, 4] 5\n",
        "[3, 4, 5] 6\n",
        "[4, 5, 6] 7\n",
        "Generate an array\n",
        "of sorted integers\n",
        "from 0 to 9.\n",
        "The sequences\n",
        "we generate will\n",
        "be sampled from\n",
        "[0 1 2 3 4 5 6].\n",
        "The target for the sequence that\n",
        "starts at data[N] will be data[N + 3].\n",
        "The sequences wil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ng8H-5h7s-OP"
      },
      "outputs": [],
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "raw_data /= std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZ1Uo6NwVQr"
      },
      "source": [
        "Listing 10.7 Instantiating datasets for training, validation, and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YllkS84FwXbI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(raw_data[:-delay], targets = temperature[delay:], sampling_rate=sampling_rate, sequence_length=sequence_length, shuffle=True, batch_size=batch_size, start_index=0, end_index=num_train_samples)\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6_9joF7wfB_"
      },
      "source": [
        "Each dataset yields a tuple (samples, targets), where samples is a batch of 256 samples, each containing 120 consecutive hours of input data, and targets is the corresponding array of 256 target temperatures. Note that the samples are randomly\n",
        "shuffled, so two consecutive sequences in a batch (like samples[0] and samples[1])\n",
        "aren’t necessarily temporally close.\n",
        "Listing 10.8 Inspecting the output of one of our datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdV3ayTxwnrw",
        "outputId": "251dbe72-a810-4be0-c8e0-047beb27aef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples shape: (256, 120, 14)\n",
            "targets shape: (256,)\n"
          ]
        }
      ],
      "source": [
        "for samples, targets in train_dataset:\n",
        "  print(\"samples shape:\", samples.shape)\n",
        "  print(\"targets shape:\", targets.shape)\n",
        "  break\n",
        "  np.mean(np.abs(preds - targets))\n",
        "# def evaluate_naive_method(dataset)\n",
        "#   total_abs_err = 0\n",
        "#   samples_seen = 0\n",
        "# for samples, targets in dataset:\n",
        "# preds = samples[:, -1, 1] * std[1] + mean[1]\n",
        "# total_abs_err += np.sum(np.abs(preds - targets))\n",
        "# samples_seen += samples.shape[0]\n",
        "# return total_abs_err / samples_seen\n",
        "# print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
        "# print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ASLjyU-4z4X"
      },
      "source": [
        "This common-sense baseline achieves a validation MAE of 2.44 degrees Celsius and a test MAE of 2.62 degrees Celsius. So if you always assume that the temperature 24 hours in the future will be the same as it is now, you will be off by two and a half degrees on average. It’s not too bad, but you probably won’t launch a weather forecasting service based on this heuristic. Now the game is to use your knowledge of deep learning to do better. Listing 10.9 Computing the common-sense baseline MAE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "QjktLII45If-",
        "outputId": "9c222188-1511-4ba9-cbce-68d80ea3a28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "819/819 [==============================] - 45s 51ms/step - loss: 13.2111 - mae: 2.8136 - val_loss: 10.3561 - val_mae: 2.5329\n",
            "Epoch 2/10\n",
            "819/819 [==============================] - 42s 51ms/step - loss: 9.2283 - mae: 2.3962 - val_loss: 10.1643 - val_mae: 2.5094\n",
            "Epoch 3/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 8.3878 - mae: 2.2832 - val_loss: 11.5998 - val_mae: 2.6867\n",
            "Epoch 4/10\n",
            "819/819 [==============================] - 47s 57ms/step - loss: 7.9110 - mae: 2.2181 - val_loss: 11.1901 - val_mae: 2.6515\n",
            "Epoch 5/10\n",
            "819/819 [==============================] - 40s 49ms/step - loss: 7.5702 - mae: 2.1702 - val_loss: 10.4958 - val_mae: 2.5586\n",
            "Epoch 6/10\n",
            "819/819 [==============================] - 41s 50ms/step - loss: 7.2988 - mae: 2.1341 - val_loss: 10.5330 - val_mae: 2.5639\n",
            "Epoch 7/10\n",
            "819/819 [==============================] - 43s 52ms/step - loss: 7.0882 - mae: 2.1036 - val_loss: 10.6764 - val_mae: 2.5866\n",
            "Epoch 8/10\n",
            "819/819 [==============================] - 43s 53ms/step - loss: 6.9049 - mae: 2.0746 - val_loss: 11.8745 - val_mae: 2.7351\n",
            "Epoch 9/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 6.7556 - mae: 2.0539 - val_loss: 11.0491 - val_mae: 2.6241\n",
            "Epoch 10/10\n",
            "819/819 [==============================] - 42s 51ms/step - loss: 6.6354 - mae: 2.0359 - val_loss: 12.8261 - val_mae: 2.8652\n",
            "405/405 [==============================] - 14s 33ms/step - loss: 10.8032 - mae: 2.5790\n",
            "Test MAE: 2.58\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 120, 14)\n",
            "(None, 1)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"jena_dense.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "epochs=10,\n",
        "validation_data=val_dataset,\n",
        "callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_dense.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history.history[\"mae\"]\n",
        "val_loss = history.history[\"val_mae\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
        "plt.title(\"Training and validation MAE\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(inputs.shape)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0v-xtbUHmZ8"
      },
      "source": [
        "10.2.4 Let’s try a 1D convolutional model\n",
        "Speaking of leveraging the right architecture priors, since our input sequences feature daily cycles, perhaps a convolutional model could work. A temporal convnet could reuse the same representations across different days, much like a spatial convnet can reuse the same representations across different locations in an image.\n",
        "You already know about the Conv2D and SeparableConv2D layers, which see their\n",
        "inputs through small windows that swipe across 2D grids. There are also 1D and even Figure 10.3 Training and validation MAE on the Jena temperatureforecasting task with a simple, densely connected networkA temperature-forecasting example 291 3D versions of these layers: Conv1D, SeparableConv1D, and Conv3D.2 The Conv1D layer relies on 1D windows that slide across input sequences, and the Conv3D layer relies on cubic windows that slide across input volumes.\n",
        "You can thus build 1D convnets, strictly analogous to 2D convnets. They’re a great fit for any sequence data that follows the translation invariance assumption (meaning that if you slide a window over the sequence, the content of the window should follow the same properties independently of the location of the window).\n",
        "Let’s try one on our temperature-forecasting problem. We’ll pick an initial window length of 24, so that we look at 24 hours of data at a time (one cycle). As we downsample the sequences (via MaxPooling1D layers), we’ll reduce the  window size accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV3d6xD2Hn2W",
        "outputId": "1eda183f-7836-4975-9268-275de5d693f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "819/819 [==============================] - 49s 51ms/step - loss: 22.4980 - mae: 3.7132 - val_loss: 15.5574 - val_mae: 3.1001\n",
            "Epoch 2/10\n",
            "819/819 [==============================] - 43s 52ms/step - loss: 15.8935 - mae: 3.1668 - val_loss: 15.0588 - val_mae: 3.0698\n",
            "Epoch 3/10\n",
            "819/819 [==============================] - 42s 51ms/step - loss: 14.4693 - mae: 3.0183 - val_loss: 14.0968 - val_mae: 2.9509\n",
            "Epoch 4/10\n",
            "819/819 [==============================] - 40s 49ms/step - loss: 13.5064 - mae: 2.9148 - val_loss: 14.2899 - val_mae: 2.9706\n",
            "Epoch 5/10\n",
            "819/819 [==============================] - 42s 50ms/step - loss: 12.8250 - mae: 2.8381 - val_loss: 14.2287 - val_mae: 2.9461\n",
            "Epoch 6/10\n",
            "819/819 [==============================] - 42s 51ms/step - loss: 12.2370 - mae: 2.7710 - val_loss: 14.2089 - val_mae: 2.9673\n",
            "Epoch 7/10\n",
            "819/819 [==============================] - 41s 49ms/step - loss: 11.7557 - mae: 2.7140 - val_loss: 13.9442 - val_mae: 2.9368\n",
            "Epoch 8/10\n",
            "819/819 [==============================] - 40s 49ms/step - loss: 11.3693 - mae: 2.6674 - val_loss: 14.0959 - val_mae: 2.9823\n",
            "Epoch 9/10\n",
            "819/819 [==============================] - 41s 50ms/step - loss: 11.0483 - mae: 2.6278 - val_loss: 14.2822 - val_mae: 2.9560\n",
            "Epoch 10/10\n",
            "819/819 [==============================] - 41s 50ms/step - loss: 10.7259 - mae: 2.5873 - val_loss: 15.5075 - val_mae: 3.0945\n",
            "405/405 [==============================] - 14s 33ms/step - loss: 15.3519 - mae: 3.1129\n",
            "Test MAE: 3.11\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Conv1D(8, 24, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Conv1D(8, 12, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Conv1D(8, 6, activation=\"relu\")(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"jena_conv.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "epochs=10,\n",
        "validation_data=val_dataset,\n",
        "callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_conv.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0msut1vIGrE"
      },
      "source": [
        "Neither the fully connected approach nor the convolutional approach did well, but that doesn’t mean machine learning isn’t applicable to this problem. The densely connected approach first flattened the timeseries, which removed the notion of time from the input data. The convolutional approach treated every segment of the data in the same way, even applying pooling, which destroyed order information. Let’s instead look at the data as what it is: a sequence, where causality and order matter. There’s a family of neural network architectures designed specifically for this use case: recurrent neural networks. Among them, the Long Short Term Memory (LSTM) layer has long been very popular. We’ll see in a minute how these models work, but let’s start by giving the LSTM layer a try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRvvV44iIPHK",
        "outputId": "27c277ca-ca50-4887-80ea-4ec4450e277a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "819/819 [==============================] - 48s 56ms/step - loss: 38.2840 - mae: 4.4748 - val_loss: 12.2013 - val_mae: 2.6763\n",
            "Epoch 2/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 10.7115 - mae: 2.5439 - val_loss: 9.7887 - val_mae: 2.4392\n",
            "Epoch 3/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 9.5855 - mae: 2.4120 - val_loss: 9.8008 - val_mae: 2.4363\n",
            "Epoch 4/10\n",
            "819/819 [==============================] - 45s 54ms/step - loss: 8.9409 - mae: 2.3305 - val_loss: 9.7080 - val_mae: 2.4270\n",
            "Epoch 5/10\n",
            "819/819 [==============================] - 45s 54ms/step - loss: 8.6030 - mae: 2.2831 - val_loss: 9.9191 - val_mae: 2.4528\n",
            "Epoch 6/10\n",
            "819/819 [==============================] - 44s 54ms/step - loss: 8.3438 - mae: 2.2494 - val_loss: 9.8104 - val_mae: 2.4342\n",
            "Epoch 7/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 8.1361 - mae: 2.2213 - val_loss: 9.9506 - val_mae: 2.4545\n",
            "Epoch 8/10\n",
            "819/819 [==============================] - 44s 53ms/step - loss: 7.9839 - mae: 2.2009 - val_loss: 10.3118 - val_mae: 2.5097\n",
            "Epoch 9/10\n",
            "819/819 [==============================] - 45s 54ms/step - loss: 7.8343 - mae: 2.1802 - val_loss: 10.3652 - val_mae: 2.5073\n",
            "Epoch 10/10\n",
            "819/819 [==============================] - 43s 52ms/step - loss: 7.7329 - mae: 2.1660 - val_loss: 10.1295 - val_mae: 2.4850\n",
            "405/405 [==============================] - 14s 33ms/step - loss: 10.6305 - mae: 2.5858\n",
            "Test MAE: 2.59\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(16)(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"jena_lstm.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "epochs=10,\n",
        "validation_data=val_dataset,\n",
        "callbacks=callbacks)\n",
        "# Listing 10.12 A simple LSTM-based model\n",
        "# Figure 10.4 Training and validation MAE on the Jena temperatureforecasting task with a 1D convnetUnderstanding recurrent neural networks 293\n",
        "model = keras.models.load_model(\"jena_lstm.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3-GSvliB3i"
      },
      "source": [
        "Listing 10.13 Pseudocode RNN\n",
        "You can even flesh out the function f: the transformation of the input and state into an output will be parameterized by two matrices, W and U, and a bias vector. It’s similar to the transformation operated by a densely connected layer in a feedforward network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn9_uFFyivBX"
      },
      "source": [
        "That’s easy enough. In summary, an RNN is a for loop that reuses quantities computed during the previous iteration of the loop, nothing more. Of course, there are many different RNNs fitting this definition that you could build—this example is one of the simplest RNN formulations. RNNs are characterized by their step function, such as the following function in this case (see figure 10.7).\n",
        "NOTE In this example, the final output is a rank-2 tensor of shape (timesteps, output_features), where each timestep is the output of the loop at\n",
        "time t. Each timestep t in the output tensor contains information about timesteps 0 to t in the input sequence—about the entire past. For this reason, in many cases, you don’t need this full sequence of outputs; you just need the\n",
        "last output (output_t at the end of the loop), because it already contains information about the entire sequence.\n",
        "10.3.1 A recurrent layer in Keras\n",
        "The process we just naively implemented in NumPy corresponds to an actual Keras\n",
        "layer—the SimpleRNN layer.\n",
        "There is one minor difference: SimpleRNN processes batches of sequences, like all other Keras layers, not a single sequence as in the NumPy example. This means it takes inputs of shape (batch_size, timesteps, input_features), rather than (timesteps, input_features). When specifying the shape argument of the initial Input(), note that you can set the timesteps entry to None, which enables your network to process sequences of arbitrary length.\n",
        "num_features = 14\n",
        "inputs = keras.Input(shape=(None, num_features))\n",
        "outputs = layers.SimpleRNN(16)(inputs)\n",
        "This is especially useful if your model is meant to process sequences of variable length.\n",
        "However, if all of your sequences have the same length, I recommend specifying a\n",
        "complete input shape, since it enables model.summary() to display output length information, which is always nice, and it can unlock some performance optimizations (see the “Note on RNN runtime performance” sidebar a little later in this chapter).\n",
        "All recurrent layers in Keras (SimpleRNN, LSTM, and GRU) can be run in two different modes: they can return either full sequences of successive outputs for each timestep (a rank-3 tensor of shape (batch_size, timesteps, output_features)) or return only the last output for each input sequence (a rank-2 tensor of shape (batch_ size, output_features)). These two modes are controlled by the return_sequences constructor argument. Let’s look at an example that uses SimpleRNN and returns only the output at the last timestep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-bqdffHixPR",
        "outputId": "ac98ca3c-ede5-4abd-d21e-a473b6ead984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16)\n"
          ]
        }
      ],
      "source": [
        "num_features = 14\n",
        "inputs = keras.Input(shape=(None, num_features))\n",
        "outputs = layers.SimpleRNN(16)(inputs)\n",
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=False)(inputs)\n",
        "print(outputs.shape)\n",
        "\n",
        "# Listing 10.16 An RNN layer that can process sequences of any length\n",
        "# Listing 10.17 An RNN layer that returns only its last output step\n",
        "# Note that\n",
        "return_sequences=False\n",
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(x)\n",
        "outputs = layers.SimpleRNN(16)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p3esoFnYkiLk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hepB2GNFkyMe",
        "outputId": "20544a34-48a3-4169-b942-791c6ac64b4e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 340s 412ms/step - loss: 27.4473 - mae: 3.8774 - val_loss: 9.6915 - val_mae: 2.4234\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 337s 411ms/step - loss: 14.7469 - mae: 2.9850 - val_loss: 9.6419 - val_mae: 2.4063\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 356s 434ms/step - loss: 13.9641 - mae: 2.8958 - val_loss: 9.3747 - val_mae: 2.3770\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 334s 407ms/step - loss: 13.4187 - mae: 2.8389 - val_loss: 10.1734 - val_mae: 2.4630\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 339s 414ms/step - loss: 12.9360 - mae: 2.7868 - val_loss: 9.4122 - val_mae: 2.3949\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 339s 414ms/step - loss: 12.4362 - mae: 2.7352 - val_loss: 9.2839 - val_mae: 2.3851\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 343s 419ms/step - loss: 12.0525 - mae: 2.6981 - val_loss: 9.3715 - val_mae: 2.3848\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 342s 418ms/step - loss: 11.7530 - mae: 2.6602 - val_loss: 9.7077 - val_mae: 2.4274\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 342s 418ms/step - loss: 11.4759 - mae: 2.6305 - val_loss: 9.8384 - val_mae: 2.4434\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 342s 417ms/step - loss: 11.3020 - mae: 2.6072 - val_loss: 9.6196 - val_mae: 2.4038\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 341s 416ms/step - loss: 11.1085 - mae: 2.5850 - val_loss: 9.6748 - val_mae: 2.4068\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 340s 415ms/step - loss: 10.9428 - mae: 2.5669 - val_loss: 9.7661 - val_mae: 2.4336\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 373s 456ms/step - loss: 10.7557 - mae: 2.5446 - val_loss: 9.8442 - val_mae: 2.4290\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 370s 451ms/step - loss: 10.6201 - mae: 2.5293 - val_loss: 9.8437 - val_mae: 2.4429\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 373s 455ms/step - loss: 10.4834 - mae: 2.5142 - val_loss: 10.2130 - val_mae: 2.4743\n",
            "Epoch 16/50\n",
            "819/819 [==============================] - 377s 460ms/step - loss: 10.3992 - mae: 2.5048 - val_loss: 10.0903 - val_mae: 2.4692\n",
            "Epoch 17/50\n",
            "819/819 [==============================] - 372s 453ms/step - loss: 10.3011 - mae: 2.4919 - val_loss: 10.3313 - val_mae: 2.5068\n",
            "Epoch 18/50\n",
            "819/819 [==============================] - 376s 459ms/step - loss: 10.1862 - mae: 2.4755 - val_loss: 10.2555 - val_mae: 2.4979\n",
            "Epoch 19/50\n",
            "819/819 [==============================] - 371s 453ms/step - loss: 10.0525 - mae: 2.4621 - val_loss: 10.2384 - val_mae: 2.4957\n",
            "Epoch 20/50\n",
            "819/819 [==============================] - 389s 474ms/step - loss: 9.9969 - mae: 2.4532 - val_loss: 10.4820 - val_mae: 2.5287\n",
            "Epoch 21/50\n",
            "819/819 [==============================] - 371s 453ms/step - loss: 9.8674 - mae: 2.4380 - val_loss: 10.7548 - val_mae: 2.5606\n",
            "Epoch 22/50\n",
            "819/819 [==============================] - 368s 449ms/step - loss: 9.8078 - mae: 2.4300 - val_loss: 10.8512 - val_mae: 2.5788\n",
            "Epoch 23/50\n",
            "819/819 [==============================] - 372s 454ms/step - loss: 9.7145 - mae: 2.4179 - val_loss: 10.6851 - val_mae: 2.5583\n",
            "Epoch 24/50\n",
            "819/819 [==============================] - 370s 451ms/step - loss: 9.7014 - mae: 2.4191 - val_loss: 10.9566 - val_mae: 2.5868\n",
            "Epoch 25/50\n",
            "819/819 [==============================] - 391s 478ms/step - loss: 9.6168 - mae: 2.4056 - val_loss: 10.9699 - val_mae: 2.5959\n",
            "Epoch 26/50\n",
            "819/819 [==============================] - 348s 425ms/step - loss: 9.5252 - mae: 2.3943 - val_loss: 11.0971 - val_mae: 2.6046\n",
            "Epoch 27/50\n",
            "819/819 [==============================] - 344s 419ms/step - loss: 9.4803 - mae: 2.3870 - val_loss: 11.3600 - val_mae: 2.6465\n",
            "Epoch 28/50\n",
            "819/819 [==============================] - 344s 420ms/step - loss: 9.4533 - mae: 2.3864 - val_loss: 11.2484 - val_mae: 2.6238\n",
            "Epoch 29/50\n",
            "819/819 [==============================] - 367s 448ms/step - loss: 9.3575 - mae: 2.3728 - val_loss: 10.9646 - val_mae: 2.6023\n",
            "Epoch 30/50\n",
            "819/819 [==============================] - 367s 448ms/step - loss: 9.3014 - mae: 2.3646 - val_loss: 11.8185 - val_mae: 2.6943\n",
            "Epoch 31/50\n",
            "819/819 [==============================] - 374s 456ms/step - loss: 9.2791 - mae: 2.3607 - val_loss: 11.4444 - val_mae: 2.6455\n",
            "Epoch 32/50\n",
            "819/819 [==============================] - 386s 471ms/step - loss: 9.2517 - mae: 2.3597 - val_loss: 10.9437 - val_mae: 2.5988\n",
            "Epoch 33/50\n",
            "819/819 [==============================] - 362s 442ms/step - loss: 9.1508 - mae: 2.3462 - val_loss: 11.6049 - val_mae: 2.6720\n",
            "Epoch 34/50\n",
            "819/819 [==============================] - 349s 426ms/step - loss: 9.1898 - mae: 2.3491 - val_loss: 11.9180 - val_mae: 2.7066\n",
            "Epoch 35/50\n",
            "819/819 [==============================] - 338s 413ms/step - loss: 9.1280 - mae: 2.3449 - val_loss: 11.7835 - val_mae: 2.6997\n",
            "Epoch 36/50\n",
            "819/819 [==============================] - 334s 407ms/step - loss: 9.1085 - mae: 2.3387 - val_loss: 11.4579 - val_mae: 2.6644\n",
            "Epoch 37/50\n",
            "819/819 [==============================] - 336s 410ms/step - loss: 9.0515 - mae: 2.3347 - val_loss: 11.9558 - val_mae: 2.7179\n",
            "Epoch 38/50\n",
            "819/819 [==============================] - 331s 404ms/step - loss: 9.0284 - mae: 2.3303 - val_loss: 11.2747 - val_mae: 2.6358\n",
            "Epoch 39/50\n",
            "819/819 [==============================] - 332s 405ms/step - loss: 8.9875 - mae: 2.3246 - val_loss: 11.3855 - val_mae: 2.6554\n",
            "Epoch 40/50\n",
            "819/819 [==============================] - 332s 406ms/step - loss: 8.9308 - mae: 2.3186 - val_loss: 11.6848 - val_mae: 2.6763\n",
            "Epoch 41/50\n",
            "819/819 [==============================] - 333s 406ms/step - loss: 8.9423 - mae: 2.3174 - val_loss: 11.8944 - val_mae: 2.6905\n",
            "Epoch 42/50\n",
            "819/819 [==============================] - 333s 406ms/step - loss: 8.8982 - mae: 2.3098 - val_loss: 11.5481 - val_mae: 2.6600\n",
            "Epoch 43/50\n",
            "819/819 [==============================] - 335s 409ms/step - loss: 8.8994 - mae: 2.3107 - val_loss: 11.3543 - val_mae: 2.6438\n",
            "Epoch 44/50\n",
            "553/819 [===================>..........] - ETA: 1:40 - loss: 8.8709 - mae: 2.3082"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"jena_lstm_dropout.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "epochs=50,\n",
        "validation_data=val_dataset,\n",
        "callbacks=callbacks)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "epochs=50,\n",
        "validation_data=val_dataset,\n",
        "callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_HiMs4Yk7cA"
      },
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEhd9z2ZkD9X"
      },
      "source": [
        "In practice, you’ll rarely work with the SimpleRNN layer. It’s generally too simplistic to be of real use. In particular, SimpleRNN has a major issue: although it should theoretically be able to retain at time t information about inputs seen many timesteps before, such long-term dependencies prove impossible to learn in practice. This is due to the vanishing gradient problem, an effect that is similar to what is observed with non-recurrent networks (feedforward networks) that are many layers deep: as you keep adding layers to a network, the network eventually becomes untrainable. The theoretical reasons for this effect were studied by Hochreiter, Schmidhuber, and Bengio in the early 1990s.3\n",
        "Thankfully, SimpleRNN isn’t the only recurrent layer available in Keras. There are two others, LSTM and GRU, which were designed to address these issues.\n",
        "Let’s consider the LSTM layer. The underlying Long Short-Term Memory (LSTM)\n",
        "algorithm was developed by Hochreiter and Schmidhuber in 1997;4 it was the culmination of their research on the vanishing gradient problem.\n",
        "This layer is a variant of the SimpleRNN layer you already know about; it adds a way to carry information across many timesteps. Imagine a conveyor belt running parallel to the sequence you’re processing. Information from the sequence can jump onto the conveyor belt at any point, be transported to a later timestep, and jump off, intact, when you need it. This is essentially what LSTM does: it saves information for later, thus preventing older signals from gradually vanishing during processing. This should\n",
        "Listing 10.18 An RNN layer that returns its full output sequence\n",
        "Listing 10.19 Stacking RNN layers\n",
        "3 See, for example, Yoshua Bengio, Patrice Simard, and Paolo Frasconi, “Learning Long-Term Dependencies\n",
        "with Gradient Descent Is Difficult,” IEEE Transactions on Neural Networks 5, no. 2 (1994).\n",
        "4 Sepp Hochreiter and Jürgen Schmidhuber, “Long Short-Term Memory,” Neural Computation 9, no. 8 (1997).298 CHAPTER 10 Deep learning for timeseries\n",
        "remind you of residual connections, which you learned about in chapter 9: it’s pretty much the same idea.\n",
        "To understand this process in detail, let’s start from the SimpleRNN cell (see figure 10.8). Because you’ll have a lot of weight matrices, index the W and U matrices in the cell, with the letter o (Wo and Uo) for output."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCoNYWbJv+KNTNB/W1QtxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}