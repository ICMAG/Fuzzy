{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICMAG/Fuzzy/blob/main/chapter05_fundamentals_of_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtuiUcEyh-xK"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZbs_Hsvh-xi"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toFMvhvLh-xu"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJvoSDjth-x2"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysW8zVA4h-yA"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBiZ2LTMh-yD"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOoB4N_Ch-yG"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYQrdUMqh-yM"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H8_Oi7sh-yS",
        "outputId": "23acd199-1adb-4403-ec60-e610a1cd457f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm2mFb9dh-yi"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRfdTIHYh-ym",
        "outputId": "b69e169c-821a-43df-d227-2b631030d756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 8s 20ms/step - loss: 0.6227 - accuracy: 0.8104 - val_loss: 0.3636 - val_accuracy: 0.8844\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2529 - accuracy: 0.9218 - val_loss: 0.1909 - val_accuracy: 0.9427\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1658 - accuracy: 0.9487 - val_loss: 0.1489 - val_accuracy: 0.9567\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1187 - accuracy: 0.9631 - val_loss: 0.1525 - val_accuracy: 0.9535\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0867 - accuracy: 0.9725 - val_loss: 0.1529 - val_accuracy: 0.9557\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0648 - accuracy: 0.9804 - val_loss: 0.1468 - val_accuracy: 0.9600\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0486 - accuracy: 0.9845 - val_loss: 0.1401 - val_accuracy: 0.9622\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.1407 - val_accuracy: 0.9634\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.1419 - val_accuracy: 0.9640\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.1355 - val_accuracy: 0.9671\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2847 - accuracy: 0.9177 - val_loss: 0.1484 - val_accuracy: 0.9569\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.1191 - accuracy: 0.9640 - val_loss: 0.1179 - val_accuracy: 0.9663\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 0.0938 - val_accuracy: 0.9712\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0554 - accuracy: 0.9840 - val_loss: 0.0862 - val_accuracy: 0.9747\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 0.0856 - val_accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.0823 - val_accuracy: 0.9785\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0843 - val_accuracy: 0.9760\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0823 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0951 - val_accuracy: 0.9765\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0852 - val_accuracy: 0.9802\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6eQGk64h-yq"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "aRM6KTkCh-yt",
        "outputId": "dea68a0d-6655-4682-d9a6-a133b4e2d873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd7d0903ed0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbgukDFJh-yx"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUsvVtrZh-y1"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTbNbIXlh-y3",
        "outputId": "56e400ff-b557-4a1a-e7b3-68f71e45eac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3165 - accuracy: 0.1033 - val_loss: 2.3065 - val_accuracy: 0.1032\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.3003 - accuracy: 0.1154 - val_loss: 2.3153 - val_accuracy: 0.1023\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.2906 - accuracy: 0.1286 - val_loss: 2.3214 - val_accuracy: 0.1009\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.2766 - accuracy: 0.1388 - val_loss: 2.3278 - val_accuracy: 0.1065\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.2593 - accuracy: 0.1529 - val_loss: 2.3370 - val_accuracy: 0.1029\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.2387 - accuracy: 0.1675 - val_loss: 2.3510 - val_accuracy: 0.1022\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.2136 - accuracy: 0.1817 - val_loss: 2.3778 - val_accuracy: 0.1046\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.1864 - accuracy: 0.1962 - val_loss: 2.3857 - val_accuracy: 0.1047\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.1563 - accuracy: 0.2142 - val_loss: 2.4045 - val_accuracy: 0.1043\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.1247 - accuracy: 0.2340 - val_loss: 2.4325 - val_accuracy: 0.1072\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.0917 - accuracy: 0.2474 - val_loss: 2.4495 - val_accuracy: 0.1070\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.0580 - accuracy: 0.2646 - val_loss: 2.4814 - val_accuracy: 0.0999\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.0235 - accuracy: 0.2781 - val_loss: 2.5139 - val_accuracy: 0.1044\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.9889 - accuracy: 0.2912 - val_loss: 2.5319 - val_accuracy: 0.1050\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.9533 - accuracy: 0.3071 - val_loss: 2.5720 - val_accuracy: 0.1014\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.9191 - accuracy: 0.3222 - val_loss: 2.5938 - val_accuracy: 0.1049\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.8825 - accuracy: 0.3385 - val_loss: 2.6347 - val_accuracy: 0.1013\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.8511 - accuracy: 0.3491 - val_loss: 2.6673 - val_accuracy: 0.0990\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.8169 - accuracy: 0.3657 - val_loss: 2.6974 - val_accuracy: 0.1027\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.7824 - accuracy: 0.3794 - val_loss: 2.7396 - val_accuracy: 0.1017\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.7502 - accuracy: 0.3889 - val_loss: 2.7809 - val_accuracy: 0.0984\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.7211 - accuracy: 0.4031 - val_loss: 2.8244 - val_accuracy: 0.1018\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.6889 - accuracy: 0.4131 - val_loss: 2.8447 - val_accuracy: 0.1013\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.6598 - accuracy: 0.4263 - val_loss: 2.8996 - val_accuracy: 0.1042\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.6304 - accuracy: 0.4366 - val_loss: 2.9305 - val_accuracy: 0.1030\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.6013 - accuracy: 0.4477 - val_loss: 2.9681 - val_accuracy: 0.1002\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.5720 - accuracy: 0.4595 - val_loss: 3.0352 - val_accuracy: 0.1033\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.5464 - accuracy: 0.4688 - val_loss: 3.0631 - val_accuracy: 0.1032\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.5180 - accuracy: 0.4793 - val_loss: 3.1086 - val_accuracy: 0.0997\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.4911 - accuracy: 0.4892 - val_loss: 3.1606 - val_accuracy: 0.1023\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.4663 - accuracy: 0.4979 - val_loss: 3.2134 - val_accuracy: 0.1062\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.4405 - accuracy: 0.5089 - val_loss: 3.2482 - val_accuracy: 0.1048\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4175 - accuracy: 0.5149 - val_loss: 3.3108 - val_accuracy: 0.1051\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3946 - accuracy: 0.5233 - val_loss: 3.3218 - val_accuracy: 0.1077\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.3718 - accuracy: 0.5303 - val_loss: 3.3836 - val_accuracy: 0.1025\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.3507 - accuracy: 0.5369 - val_loss: 3.4319 - val_accuracy: 0.1041\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.3269 - accuracy: 0.5480 - val_loss: 3.4762 - val_accuracy: 0.1050\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.3029 - accuracy: 0.5569 - val_loss: 3.5105 - val_accuracy: 0.1058\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.2831 - accuracy: 0.5613 - val_loss: 3.5737 - val_accuracy: 0.1066\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.2629 - accuracy: 0.5701 - val_loss: 3.6350 - val_accuracy: 0.1017\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.2453 - accuracy: 0.5795 - val_loss: 3.6639 - val_accuracy: 0.1055\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.2221 - accuracy: 0.5855 - val_loss: 3.7171 - val_accuracy: 0.1052\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1999 - accuracy: 0.5949 - val_loss: 3.7532 - val_accuracy: 0.1036\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1846 - accuracy: 0.5985 - val_loss: 3.8487 - val_accuracy: 0.1011\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1662 - accuracy: 0.6065 - val_loss: 3.8616 - val_accuracy: 0.1058\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1473 - accuracy: 0.6126 - val_loss: 3.9253 - val_accuracy: 0.1028\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1295 - accuracy: 0.6203 - val_loss: 3.9775 - val_accuracy: 0.1035\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.1134 - accuracy: 0.6278 - val_loss: 4.0356 - val_accuracy: 0.1037\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0976 - accuracy: 0.6298 - val_loss: 4.0920 - val_accuracy: 0.1037\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0791 - accuracy: 0.6398 - val_loss: 4.1643 - val_accuracy: 0.0997\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0625 - accuracy: 0.6433 - val_loss: 4.2040 - val_accuracy: 0.1042\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0461 - accuracy: 0.6504 - val_loss: 4.2422 - val_accuracy: 0.1047\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0312 - accuracy: 0.6571 - val_loss: 4.3247 - val_accuracy: 0.1022\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0158 - accuracy: 0.6602 - val_loss: 4.3579 - val_accuracy: 0.1054\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0005 - accuracy: 0.6666 - val_loss: 4.4151 - val_accuracy: 0.1009\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9841 - accuracy: 0.6716 - val_loss: 4.5000 - val_accuracy: 0.1036\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9714 - accuracy: 0.6748 - val_loss: 4.5483 - val_accuracy: 0.1035\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9541 - accuracy: 0.6834 - val_loss: 4.6229 - val_accuracy: 0.1021\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9428 - accuracy: 0.6868 - val_loss: 4.6394 - val_accuracy: 0.1007\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9277 - accuracy: 0.6913 - val_loss: 4.7145 - val_accuracy: 0.0995\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9162 - accuracy: 0.6948 - val_loss: 4.7742 - val_accuracy: 0.1026\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.9021 - accuracy: 0.6997 - val_loss: 4.8307 - val_accuracy: 0.1008\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8886 - accuracy: 0.7051 - val_loss: 4.8862 - val_accuracy: 0.1042\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8776 - accuracy: 0.7097 - val_loss: 4.9579 - val_accuracy: 0.0996\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8652 - accuracy: 0.7159 - val_loss: 4.9713 - val_accuracy: 0.1002\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8506 - accuracy: 0.7190 - val_loss: 5.0858 - val_accuracy: 0.1037\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8375 - accuracy: 0.7237 - val_loss: 5.1261 - val_accuracy: 0.1044\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8281 - accuracy: 0.7259 - val_loss: 5.1875 - val_accuracy: 0.1041\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8142 - accuracy: 0.7331 - val_loss: 5.2788 - val_accuracy: 0.1038\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.8042 - accuracy: 0.7343 - val_loss: 5.2912 - val_accuracy: 0.1037\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7935 - accuracy: 0.7391 - val_loss: 5.3995 - val_accuracy: 0.1044\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7819 - accuracy: 0.7420 - val_loss: 5.4433 - val_accuracy: 0.1047\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7695 - accuracy: 0.7477 - val_loss: 5.4999 - val_accuracy: 0.1040\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7613 - accuracy: 0.7490 - val_loss: 5.5924 - val_accuracy: 0.1028\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7485 - accuracy: 0.7549 - val_loss: 5.6503 - val_accuracy: 0.1025\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7375 - accuracy: 0.7583 - val_loss: 5.7066 - val_accuracy: 0.1027\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7269 - accuracy: 0.7618 - val_loss: 5.7110 - val_accuracy: 0.1028\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7201 - accuracy: 0.7627 - val_loss: 5.8352 - val_accuracy: 0.0994\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7098 - accuracy: 0.7695 - val_loss: 5.8388 - val_accuracy: 0.1030\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6984 - accuracy: 0.7717 - val_loss: 5.9393 - val_accuracy: 0.1024\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6909 - accuracy: 0.7750 - val_loss: 6.0375 - val_accuracy: 0.1024\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6805 - accuracy: 0.7784 - val_loss: 6.1117 - val_accuracy: 0.1032\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6715 - accuracy: 0.7820 - val_loss: 6.1351 - val_accuracy: 0.1027\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6605 - accuracy: 0.7853 - val_loss: 6.2166 - val_accuracy: 0.1018\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.7874 - val_loss: 6.3277 - val_accuracy: 0.1026\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6429 - accuracy: 0.7918 - val_loss: 6.3575 - val_accuracy: 0.1024\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6364 - accuracy: 0.7926 - val_loss: 6.4392 - val_accuracy: 0.1037\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6290 - accuracy: 0.7943 - val_loss: 6.4330 - val_accuracy: 0.1010\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6176 - accuracy: 0.8001 - val_loss: 6.5537 - val_accuracy: 0.1027\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6105 - accuracy: 0.8022 - val_loss: 6.6321 - val_accuracy: 0.1011\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6025 - accuracy: 0.8054 - val_loss: 6.6442 - val_accuracy: 0.1037\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5950 - accuracy: 0.8064 - val_loss: 6.7697 - val_accuracy: 0.1037\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5866 - accuracy: 0.8118 - val_loss: 6.7631 - val_accuracy: 0.1034\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5779 - accuracy: 0.8128 - val_loss: 6.8676 - val_accuracy: 0.1033\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5731 - accuracy: 0.8152 - val_loss: 6.9175 - val_accuracy: 0.1019\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5626 - accuracy: 0.8183 - val_loss: 7.0331 - val_accuracy: 0.1018\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5569 - accuracy: 0.8195 - val_loss: 7.0220 - val_accuracy: 0.1030\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5516 - accuracy: 0.8224 - val_loss: 7.1073 - val_accuracy: 0.1030\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5411 - accuracy: 0.8264 - val_loss: 7.2073 - val_accuracy: 0.1031\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.5367 - accuracy: 0.8272 - val_loss: 7.2686 - val_accuracy: 0.0992\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7cc2a9650>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcKQcdA6h-y8"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA759WQMh-zA"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtkHNEcNh-zC"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krG4MeLmh-zD"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX7PcU1jh-zG"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_n7eJRh-zH"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT1glsrkh-zJ"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1xTO1ah-zL"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWl__zWNh-zO"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRAkFDOqh-zP"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzTi_qlkh-zP"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-rGELKh-zP"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miwAymETh-zQ"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY46vMmSh-zS"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv4NOPAIh-zT",
        "outputId": "2ae880f9-9ae5-438d-d1ea-56322d517057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 875.3661 - accuracy: 0.4258 - val_loss: 2.3349 - val_accuracy: 0.2213\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 4.5534 - accuracy: 0.2659 - val_loss: 86.1877 - val_accuracy: 0.3273\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.8542 - accuracy: 0.2584 - val_loss: 2.3132 - val_accuracy: 0.2124\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.7185 - accuracy: 0.2282 - val_loss: 2.5829 - val_accuracy: 0.2402\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.6294 - accuracy: 0.2415 - val_loss: 2.3955 - val_accuracy: 0.2578\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.4121 - accuracy: 0.2572 - val_loss: 2.0480 - val_accuracy: 0.2621\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.9834 - accuracy: 0.2536 - val_loss: 2.1284 - val_accuracy: 0.2249\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.8252 - accuracy: 0.2978 - val_loss: 2.9174 - val_accuracy: 0.3581\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.4103 - accuracy: 0.2668 - val_loss: 2.7591 - val_accuracy: 0.2793\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.4403 - accuracy: 0.2817 - val_loss: 2.0718 - val_accuracy: 0.2838\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7c7a33b50>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogbEawJh-zV"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a31-lgLxh-zW"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AriQzUkZh-zZ"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JMPUQJrh-za"
      },
      "source": [
        "### Increasing model capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv4IwoT5h-zi"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz7gIZbLh-zk"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_H9CMQuh-zn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_small_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4MwA5Qqh-zp"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtBcMaiWh-zu"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJwMeWcuh-zw"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LWgifxIh-zy"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mARlrsE5h-z1"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKg1A6WAh-z3"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIGH_54Uh-z5"
      },
      "source": [
        "#### Reducing the network's size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0GQ37Snh-z5"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4POiUyjh-z_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uP8KiXnh-0A"
      },
      "source": [
        "**Version of the model with lower capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvVAUimhh-0A"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbYGAQ6th-0B"
      },
      "source": [
        "**Version of the model with higher capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cnm_0Y8Kh-0B"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_larger_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C_rMUEuh-0B"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qko_cGPh-0B"
      },
      "source": [
        "**Adding L2 weight regularization to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9UpwX9zh-0C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkre8c_8h-0C"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBgMAnOIh-0D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNIJtKzgh-0F"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSrSEQmeh-0G"
      },
      "source": [
        "**Adding dropout to the IMDB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiFP99Tvh-0I"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5fml5Aeh-0L"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}